{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Master File\n",
    "\n",
    "#### This notebook collates and cleans a number of files we recieved from the buildings \n",
    "#### department. It outputs a shapefile and a csv of all the building data. \n",
    "\n",
    "#### NYU CUSP Small Cities Team - Summer 2017\n",
    "#### Made with Python 2.7 (anaconda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Input files should all be placed in Raw folder. \n",
    "#####\n",
    "##### \"Housing Action Type Code File.xlsx\"\n",
    "##### \"Housing Case Type Code Master File.xlsx\"\n",
    "##### \"Housing ce300ap Case Action History.csv\"\n",
    "##### \"Housing Code Enforcement Case Master File.xlsx\"\n",
    "##### \"Housing Location Master File.xlsx\"\n",
    "\n",
    "##### Note* Location Master Ancillary File is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is in Data->Raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set Input/Output path variables.  This accesses data from the Raw Data File\n",
    "uppath = \"..\"\n",
    "dpath = \"Data\"\n",
    "inpath = \"Raw\"\n",
    "procdatapath = \"Processed\"\n",
    "shapepath = \"Shapefiles\"\n",
    "outpath = \"Interim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the file Names\n",
    "fname1 = \"Housing Action Type Code File.xlsx\"\n",
    "fname2 = \"Housing Case Type Code Master File.xlsx\"\n",
    "fname3 = \"Housing ce300ap Case Action History.csv\"\n",
    "fname4 = \"Housing Code Enforcement Case Master File.xlsx\"\n",
    "fname5 = \"Housing Location Master File.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the import paths \n",
    "infile1 = os.path.join(uppath, dpath, inpath, fname1)\n",
    "infile2 = os.path.join(uppath, dpath, inpath, fname2)\n",
    "infile3 = os.path.join(uppath, dpath, inpath, fname3)\n",
    "infile4 = os.path.join(uppath, dpath, inpath, fname4)\n",
    "infile5 = os.path.join(uppath, dpath, inpath, fname5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the Data Into pandas\n",
    "action_type_code = pd.read_excel(infile1)\n",
    "case_type_code = pd.read_excel(infile2)\n",
    "case_action_history = pd.read_csv(infile3)\n",
    "code_enforce_case = pd.read_excel(infile4)\n",
    "location_master = pd.read_excel(infile5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create address for geocoding on the location master file\n",
    "def clean_address (row):\n",
    "    '''\n",
    "    Make new address column for merging & geocoding\n",
    "    Return value into new column\n",
    "    '''\n",
    "    if pd.isnull(row[\"Street Dir.\"]):\n",
    "        value = str(row[\"Street#\"]) + \" \" + str(row[\"Street Name\"]) + \" Cleveland Heights \" + str(row[\"Zip\"])\n",
    "    else:\n",
    "        value = str(row[\"Street#\"]) + \" \" + str(row[\"Street Dir.\"]) + \" \" + str(row[\"Street Name\"]) + \" Cleveland Heights \" + str(row[\"Zip\"])\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply the function to create address for geocoding and merge operation\n",
    "location_master[\"address2\"] = location_master.apply(clean_address, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#In location master file.  Add old column names to a list. Add new column names \n",
    "#to a list.  \n",
    "\n",
    "old_loc_names = [u'Location ID',               u'Street#',\n",
    "                 u'Street Dir.',           u'Street Name',\n",
    "                u'Apartment ID',                   u'Zip',\n",
    "               u'Carrier Route',           u'Owners Name',\n",
    "                  u'Owner Type',      u'Owners Address 2',\n",
    "            u'Owners Address 3',            u'Owners Zip',\n",
    "        u'Owners Carrier Route',      u'Owners Area Code',\n",
    "                u'Owners Phone',        u'Land Key Sect1',\n",
    "              u'Land Key Sect2',        u'Land Key Sect3',\n",
    "              u'Land Key Sect4',        u'Land Key Sect5',\n",
    "              u'Land Key Sect6',        u'Land Key Sect7',\n",
    "              u'Land Key Sect8',        u'Land Key Sect9',\n",
    "             u'Land Key Sect10',   u'Parcel_Address Flag',\n",
    "       u'Alternate Location ID',      u'Street Qualifier',\n",
    "                     u'Acreage',     u'Property Use Code',\n",
    "        u'Undivided Interest %',         u'User Defined1',\n",
    "               u'User Defined2',         u'User Defined3',\n",
    "                    u'address2']\n",
    "\n",
    "new_loc_names = [u'Location_ID',               u'Street_num',\n",
    "                 u'Street_Dir.',           u'Street_Name',\n",
    "                u'Apartment_ID',                   u'Zip',\n",
    "               u'Carrier_Route',           u'Owners_Name',\n",
    "                  u'Owner_Type',      u'Owners_Address2',\n",
    "            u'Owners_Address3',            u'Owners_Zip',\n",
    "        u'Owners_CarrierRoute',      u'Owners_Area_Code',\n",
    "                u'Owners_Phone',        u'Land_Key_Sect1',\n",
    "              u'Land_Key_Sect2',        u'Land_Key_Sect3',\n",
    "              u'Land_Key_Sect4',        u'Land_Key_Sect5',\n",
    "              u'Land_Key_Sect6',        u'Land_Key_Sect7',\n",
    "              u'Land_Key_Sect8',        u'Land_Key_Sect9',\n",
    "             u'Land_Key_Sect10',   u'Parcel_AddressFlag',\n",
    "       u'AlternateLocationID',      u'Street_Qualifier',\n",
    "                     u'Acreage',     u'PropertyUseCode',\n",
    "        u'Undivided Interest %',         u'UserDefined1',\n",
    "               u'UserDefined2',         u'UserDefined3',\n",
    "                    u'address2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename the columns\n",
    "location_master.rename(columns=dict(zip(old_loc_names, new_loc_names)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set file name\n",
    "loc_master_clean_excel = \"loc_master_clean.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_master_clean_csv = \"loc_master_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/Interim/loc_master_clean.xlsx'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create output path string\n",
    "loc_master_cleanOUTxl = os.path.join(uppath, dpath, outpath, loc_master_clean_excel)\n",
    "loc_master_cleanOUTxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Data/Interim/loc_master_clean.csv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_master_cleanOUTcsv = os.path.join(uppath, dpath, outpath, loc_master_clean_csv)\n",
    "loc_master_cleanOUTcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to file excel\n",
    "\n",
    "location_master.to_excel(loc_master_cleanOUTxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export to csv\n",
    "#location_master.to_csv(loc_master_cleanOUTcsv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Case History with the Action Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge the Case History onto the Action-type codes. \n",
    "case_action_merge = pd.merge(case_action_history, action_type_code, left_on = \"Action_Type_Code\",\\\n",
    "                             right_on = \"Action Typ Code\", left_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename the columns in the new case action merge file\n",
    "#Old column names in a list\n",
    "case_old = [u'Case_Year',                 u'Case#',\\\n",
    "                 u'Action_Seq#',      u'Action_Type_Code',\\\n",
    "                 u'Action_Flag', u'Next_Action_#_of_Days',\\\n",
    "               u'Action_Number',       u'Action Typ Code',\\\n",
    "            u'Action Code Desc',           u'Action Flag',\\\n",
    "       u'Action Letter Library',         u'Action Letter',\\\n",
    "           u'Action Letter Doc',  u'Print Violation Flag']\n",
    "\n",
    "#New column names in a list\n",
    "case_new = [u'Case_Year',                 u'Case_num',\\\n",
    "                 u'Action_Seq_num',      u'Action_Type_Code',\\\n",
    "                 u'Action_Flag', u'Next_Action_#_of_Days',\\\n",
    "               u'Action_Number',       u'Action_Typ_Code',\\\n",
    "            u'Action_Code_Desc',           u'Action_Flag',\\\n",
    "       u'Action_Letter_Library',         u'Action_Letter',\\\n",
    "           u'Action_Letter_Doc',  u'Print_Violation_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rename columns in the new merged file using the lists. \n",
    "\n",
    "case_action_merge.rename(columns=dict(zip(case_old, case_new)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create file names\n",
    "case_action_mergexl = 'case_action_merge.xlsx'\n",
    "case_action_mergecsv = 'case_action_merge.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create output strings\n",
    "case_action_mergeOUTxl = os.path.join(uppath, dpath, outpath, case_action_mergexl)\n",
    "case_action_mergeOUTcsv = os.path.join(uppath, dpath, outpath, case_action_mergecsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to file excel\n",
    "\n",
    "#case_action_merge.to_excel(case_action_mergeOUTxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "\n",
    "#case_action_merge.to_csv(case_action_mergeOUTcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Codes and Code Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge codes into case type codes\n",
    "\n",
    "code_enforce_merge = pd.merge(code_enforce_case, case_type_code, left_on = \"Case Type Code\",\\\n",
    "                             right_on = \"Case Type Code\", left_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rename columns lists\n",
    "\n",
    "#The original column names\n",
    "code_enforce_old = [u'Case Yr', u'Case Number', u'Land ID #', u'Case Status',\\\n",
    "       u'Last Inspection #', u'Case Type Code', u'Case Inspector',\\\n",
    "       u'Tenant Name', u'Tenant #', u'Case Origination Code',\\\n",
    "       u'Code Enforcement Board#', u'Case Type Description',\\\n",
    "       u'Responsible Department']\n",
    "\n",
    "#New columns; the ones we want\n",
    "code_enforce_old_new = [u'Case_Yr', u'Case_Number', u'Land_ID', u'Case_Status',\\\n",
    "       u'Last_Inspection_num', u'Case_Type_Code', u'Case_Inspector',\\\n",
    "       u'Tenant_Name', u'Tenant_num', u'Case_Origination_Code',\\\n",
    "       u'Code_Enforcement_Boardnum', u'Case_Type_Description',\\\n",
    "       u'Responsible_Department']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#rename columns\n",
    "code_enforce_merge.rename(columns=dict(zip(code_enforce_old, code_enforce_old_new)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create file names\n",
    "code_enforce_mergexl = 'code_enforce_merge.xlsx'\n",
    "code_enforce_mergecsv = 'DD_code_enforce_merge.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create output strings\n",
    "code_enforce_mergeOUTxl = os.path.join(uppath, dpath, outpath, code_enforce_mergexl)\n",
    "code_enforce_mergeOUTcsv = os.path.join(uppath, dpath, outpath, code_enforce_mergecsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to file excel\n",
    "\n",
    "#code_enforce_merge.to_excel(code_enforce_mergeOUTxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "\n",
    "#code_enforce_merge.to_csv(code_enforce_mergeOUTcsv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Code description onto Case Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge Code description to code actions\n",
    "\n",
    "code_case_all = pd.merge(code_enforce_merge, case_action_merge, left_on = \"Case_Number\",\\\n",
    "                             right_on = \"Case_num\", indicator=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Locations onto all the code Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge locations and code cases\n",
    "\n",
    "location_code_master = pd.merge(location_master, code_case_all, left_on = \"Location_ID\",\\\n",
    "                             right_on = \"Land_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_code_masterxl = 'location_code_master.xlsx'\n",
    "location_code_mastercsv = 'location_code_master.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create output strings\n",
    "location_code_masterOUTxl = os.path.join(uppath, dpath, outpath, location_code_masterxl)\n",
    "location_code_masterOUTcsv = os.path.join(uppath, dpath, outpath, location_code_mastercsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to file excel\n",
    "#uncomment to export\n",
    "\n",
    "#location_code_master.to_excel(location_code_masterOUTxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "#Uncomment to run\n",
    "\n",
    "#location_code_master.to_csv(location_code_masterOUTcsv, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in Geocoded address and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RawgeocodeFile = \"House_location_geocodes_All.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set file string for import\n",
    "geofileImport = os.path.join(uppath, dpath, outpath, RawgeocodeFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Geocoded address file\n",
    "\n",
    "all_geocode = pd.read_csv(geofileImport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop crap columns from Geocoded file\n",
    "\n",
    "all_geocode.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge Geocodes onto location file using address feild\n",
    "\n",
    "location_code_final2 = pd.merge(location_code_master, all_geocode.drop_duplicates(subset=['address']),\\\n",
    "                                how = \"left\", left_on = \"address2\",\\\n",
    "                             right_on = \"address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Put uneeded columns in a list\n",
    "\n",
    "finaldropcols = ['_merge', 'Tenant_num', 'Carrier_Route', 'Owners_CarrierRoute', 'UserDefined3',\\\n",
    "                'UserDefined2', 'UserDefined3', 'address', 'Case_Inspector',\\\n",
    "                 'Responsible_Department', 'Code_Enforcement_Boardnum', 'Land_Key_Sect4', 'Land_Key_Sect5',\\\n",
    "                 'Land_Key_Sect6', 'Land_Key_Sect7', 'Land_Key_Sect8', 'Land_Key_Sect9', 'Land_Key_Sect10',\\\n",
    "                 'AlternateLocationID', 'Owners_Phone',\\\n",
    "                 'Undivided Interest %', 'Acreage', 'Action_Letter']\n",
    "                 \n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#More uneeded columns\n",
    "\n",
    "finaldropcols2 = ['Action_Letter_Library', 'Parcel_AddressFlag', 'Case_num', 'Action_Typ_Code',\\\n",
    "                  'Case_Yr', 'UserDefined1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop columns from first list\n",
    "location_code_final2.drop(finaldropcols2, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Drop columns from second\n",
    "location_code_final2.drop(finaldropcols, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop Nan's from coordinate feild\n",
    "location_code_final2.dropna(subset=[\"coordinate\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Lat and Long column\n",
    "#Change them to Pointly points\n",
    "#Equip the DataFrame with shapefile points.\n",
    "location_code_final2['latitude'] = [float(str(row['coordinate']).split(',')[0][1:]) for ix,row in location_code_final2.iterrows()]\n",
    "location_code_final2['longitude'] = [float(str(row['coordinate']).split(',')[1][1:-1]) for ix,row in location_code_final2.iterrows()]\n",
    "geometry1 = gpd.GeoSeries([Point(xy) for xy in zip(location_code_final2.longitude, location_code_final2.latitude)])\n",
    "location_code_final2 = gpd.GeoDataFrame(location_code_final2, geometry=geometry1)\n",
    "location_code_final2.crs = {'init' :'epsg:4326'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create address for address matchingmatch addresses \n",
    "def owner_occupied (row):\n",
    "    '''\n",
    "    detemine if a building is owner occupied by comparing two address fields \n",
    "    Returns 1 for owner occupied\n",
    "    Return 0 for not owner occupied\n",
    "    '''\n",
    "    #Define actual address\n",
    "    if pd.isnull(row[\"Street_Dir.\"]):\n",
    "        value1 = str(row[\"Street_num\"]) + \" \" + str(row[\"Street_Name\"]) + \" \" + str(row[\"Zip\"])\n",
    "    else:\n",
    "        value1 = str(row[\"Street_num\"]) + \" \" + str(row[\"Street_Dir.\"]) + \" \" + str(row[\"Street_Name\"]) + \" \" +\\\n",
    "        str(row[\"Zip\"])\n",
    "    \n",
    "    #Define Owner Address \n",
    "    value2 = str(row[\"Owners_Address3\"]) + \" \" + str(row[\"Owners_Zip\"])\n",
    "    \n",
    "    #If owner zip and zip do not match return 0; if they do compare full string\n",
    "    if str(row[\"Zip\"]) != str(row[\"Owners_Zip\"]):\n",
    "        return 0\n",
    "    #Comapre full String\n",
    "    if str(value1) == str(value2): \n",
    "        return 1\n",
    "    else:\n",
    "        return 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_code_final2[\"own_occupd\"] = location_code_final2.apply(owner_occupied, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geoFileExport_FileName = \"code_viol_Dbase.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Delete\n",
    "path34543 = \"~/Users/trondheim/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/Users/trondheim/Desktop/'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete\n",
    "path34543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/Danny1/Documents/NYU/SmallCities-Performance-Analysis/Cleveland_Heights/Code'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set file string for export\n",
    "geoFileExport = os.path.join(uppath, dpath, procdatapath, shapepath, geoFileExport_FileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-df13f0420ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlocation_code_final2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../Data/interim/Code_Enfocement.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Danny1/anaconda/lib/python2.7/site-packages/geopandas/geodataframe.pyc\u001b[0m in \u001b[0;36mto_file\u001b[0;34m(self, filename, driver, schema, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \"\"\"\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Danny1/anaconda/lib/python2.7/site-packages/geopandas/io/file.pyc\u001b[0m in \u001b[0;36mto_file\u001b[0;34m(df, filename, driver, schema, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m                     schema=schema, **kwargs) as c:\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Danny1/anaconda/lib/python2.7/site-packages/fiona/collection.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;34m\"\"\"Stages a record for writing to disk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Danny1/anaconda/lib/python2.7/site-packages/fiona/collection.pyc\u001b[0m in \u001b[0;36mwriterecords\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"collection not open for writing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.WritingSession.writerecs (fiona/ogrext2.c:18403)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfiona/ogrext.pyx\u001b[0m in \u001b[0;36mfiona.ogrext.OGRFeatureBuilder.build (fiona/ogrext2.c:5755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#location_code_final2.to_file(\"../Data/interim/Code_Enfocement.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Break Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_export_FileName = \"code_viol_Dbase.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csvFileExport = os.path.join(uppath, dpath, outpath, csv_export_FileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#location_code_final2.to_csv(csvFileExport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try to export to shapefile\n",
    "#WOnky with DateTimes\n",
    "#location_code_final2.to_file(geoFileExport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code above cleans and creates the master database type file.  The code below is supposed to aggregate by address the negative actions per property "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Place negative action codes in a list\n",
    "\n",
    "neg_actions = [\"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"VR\", \"N1\", \"N2\", \"N3\", \"NA\", \"I1\", \"I2\", \"CS\", \"CT\", \"C1\", \"C2\", \"C3\", \"C4\",\\\n",
    "\"C5\", \"C6\", \"CA\", \"CB\",\\\n",
    "\"CC\", \"CD\", \"CE\", \"CF\", \"CG\", \"CH\", \"CI\", \"CJ\", \"CK\", \"CL\", \"CM\", \"CN\", \"CO\", \"CP\", \"CQ\", \"CS\", \"CT\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a mask to only grab negative actions from the master file\n",
    "neg_mask = location_code_final2[\"Action_Type_Code\"].isin(neg_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a GeoPandas data frame using the negative mask on location master\n",
    "negative_master = gpd.GeoDataFrame(location_code_final2[neg_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "owners = gpd.read_file('../Data/Interim/Master_Building/CH_Only_Clip.shp')\n",
    "owners = owners[['PARCEL_ID', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "owners.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Danny1/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "code_enforcement = negative_master[['Action_Code_Desc', 'Case_Status', 'Case_Year', 'geometry']]\n",
    "code_enforcement.crs = {'init' :'epsg:4326'}\n",
    "code_enforcement.dropna(inplace=True)\n",
    "code_enforcement = gpd.sjoin(code_enforcement, owners, how='inner', op='intersects')\n",
    "code_enforcement.drop(['index_right'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code_enforcement.to_csv('../Data/Interim/Neg_Actions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make dictionary to define aggregation\n",
    "\n",
    "aggro4 = {\"Case_Type_Code\":lambda x:x.value_counts().index[0],\"Case_Year\":lambda x: 2017 - max(x), \"Action_Type_Code\":\"count\", \"geometry\":\"first\",\"address2\":\"first\", \"own_occupd\":\"first\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Aggregate the data onto the location ID field\n",
    "\n",
    "commondf = negative_master.groupby(\"Location_ID\").agg(aggro4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the column names\n",
    "commondf.columns = ['com_case', 'geometry', 'address', 'negCodecnt', 'last_case', 'own_occup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop Geometry column\n",
    "commondf.drop('geometry', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reset Index\n",
    "commondf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge code violations with the housing geocode file\n",
    "code_viol_agg_final = pd.merge(commondf, all_geocode.drop_duplicates(subset=['address']),\\\n",
    "                                how = \"left\", left_on = \"address\",\\\n",
    "                             right_on = \"address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Name the file\n",
    "fname_codviolagg = \"DD_code_viol_agg.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the output path\n",
    "code_viol_agg_finalOUTcsv = os.path.join(uppath, dpath, outpath, fname_codviolagg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "code_viol_agg_final.to_csv(code_viol_agg_finalOUTcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##End of code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
